# RAG-Pipeline
This project implements a Retrieval-Augmented Generation (RAG) pipeline using Google's Gemini model as the LLM, ChromaDB as the vector database, and external knowledge extracted from PDFs.
# âœ¨ Features
LLM-Powered Responses: Uses Gemini to generate context-aware answers.
Efficient Retrieval: Stores and retrieves document embeddings using ChromaDB.
PDF Knowledge Integration: Enhances LLM responses with external PDF-based information.
Scalable & Modular: Designed for easy adaptation and expansion.
# ðŸ“Œ Tech Stack
LLM: Gemini Model
Vector Database: ChromaDB
Document Processing: PDF parsing and embedding generation
Frameworks: Python, LangChain (if applicable)
# ðŸš€ Setup & Usage
Clone the repository
Install dependencies
Add your PDF files and configure the pipeline
Run the RAG system to retrieve and generate answers
